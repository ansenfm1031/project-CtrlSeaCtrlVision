import paho.mqtt.client as mqtt
import cv2
import numpy as np
from openvino.runtime import Core
import torch
import torch.nn as nn
from PIL import Image
from torchvision import transforms, models
import os
import time
import sys
import json 
from datetime import datetime, timezone
# ====================================================
# 0. ê³ ì • ì¹´ë©”ë¼ í• ë‹¹ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸ (ìˆ˜ì •ëœ ë¶€ë¶„ 1/2)
# camera_init_robust.py íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ê²½ë¡œì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# ====================================================
# find_camera_by_vid_pid í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from camera_init_robust import find_camera_by_vid_pid 

# ====================================================
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ====================================================

# MQTT ì„¤ì •
BROKER = "10.10.14.73"
PORT = 1883
TOPIC_BASE = "project/vision" # í† í”½ ì ‘ë‘ì‚¬

# AD ëª¨ë“ˆ ëª…í™•íˆ ì§€ì • ë° í† í”½ ë¶„ë¦¬
AD_MODULE = "AD"
RAW_TOPIC = TOPIC_BASE + "/" + AD_MODULE + "/RAW"
ALERT_TOPIC = TOPIC_BASE + "/" + AD_MODULE + "/ALERT" # ê²½ê³  í† í”½ë„ AD ì „ìš©ìœ¼ë¡œ ë¶„ë¦¬
def now_str():
    """ISO 8601 í˜•ì‹ì˜ í˜„ì¬ UTC ì‹œê°ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

# =======================
# 2. ëª¨ë¸ ê²½ë¡œ ì„¤ì • ë° ìœ íš¨ì„± ê²€ì‚¬
# (ëª¨ë“  ëª¨ë¸ íŒŒì¼ì€ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)
# =======================
det_xml = "models/Detection.xml"
det_bin = "models/Detection.bin"

cls_xml = "models/Classification.xml"
cls_bin = "models/Classification.bin"

DEPLOYMENT_FILE = "models/deployed_obstacle_detector.pt"

ALL_MODEL_PATHS = [det_xml, det_bin, cls_xml, cls_bin, DEPLOYMENT_FILE]
for path in ALL_MODEL_PATHS:
    if not os.path.exists(path):
        print(f"[{now_str()}] âŒ CRITICAL: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        sys.exit(1) # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ

# =======================
# 3. ì „ì—­ ê°ì²´ ë° ìƒìˆ˜
# =======================
ie = Core()
det_compiled = None
det_input_layer = None
det_output_layer = None
cls_compiled = None
cls_input_layer = None
cls_output_layer = None
cls_h, cls_w = 0, 0
cap = None
deployed_model = None

class_names = ["Buoy", "Reef", "Island", "Ship", "Lighthouse"]
last_frame_boxes = [] # NMS/ìŠ¤ë¬´ë”©ì„ ìœ„í•œ ì´ì „ í”„ë ˆì„ ë°•ìŠ¤
OPTIMAL_THRESHOLD = 0.7 # Anomaly Detection ì„ê³„ê°’
MODEL_INPUT_SIZE = 224
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]

inference_transforms = transforms.Compose([
    transforms.Resize((MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(MEAN, STD)
])


# =======================
# 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (NMS, IoU, Preprocessing)
# (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# =======================

def nms(boxes, scores, score_threshold=0.5, iou_threshold=0.5):
    """Non-Maximum Suppression"""
    if not boxes: return [], []
    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold, iou_threshold)
    if len(indices) > 0:
        indices = indices.flatten()
        return [boxes[i] for i in indices], [scores[i] for i in indices]
    return [], []

def iou(box1, box2):
    """Intersection over Union ê³„ì‚°"""
    # box1, box2: [x, y, w, h]
    x1, y1, w1, h1 = box1
    x2, y2, w2, h2 = box2
    
    xi1 = max(x1, x2)
    yi1 = max(y1, y2)
    xi2 = min(x1 + w1, x2 + w2)
    yi2 = min(y1 + h1, y2 + h2)
    
    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    union_area = w1 * h1 + w2 * h2 - inter_area
    return inter_area / union_area if union_area > 0 else 0

def enhance_low_light(image):
    """CLAHEë¥¼ ì´ìš©í•œ ì €ì¡°ë„ ê°œì„ """
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
    return enhanced_img

def dehaze(image):
    """Dark Channel Priorë¥¼ ì´ìš©í•œ Dehazing"""
    min_channel = np.min(image, axis=2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
    dark_channel = cv2.erode(min_channel, kernel)
    A = np.max(dark_channel)
    t = 1 - 0.95 * dark_channel / A
    t = np.clip(t, 0.1, 1)
    J = np.empty_like(image, dtype=np.float32)
    for c in range(3):
        J[:,:,c] = (image[:,:,c].astype(np.float32) - A) / t + A
    J = np.clip(J, 0, 255).astype(np.uint8)
    return J

# =======================
# 5. ì´ˆê¸°í™” í•¨ìˆ˜ (ëª¨ë“  ëª¨ë¸ ë¡œë“œ ë° ì¹´ë©”ë¼ ì´ˆê¸°í™”)
# =======================

def initialize_vision():
    """OpenVINO ëª¨ë¸, PyTorch ëª¨ë¸ ë° ì¹´ë©”ë¼ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global det_compiled, det_input_layer, det_output_layer
    global cls_compiled, cls_input_layer, cls_output_layer
    global cls_h, cls_w, cap, deployed_model
    
    try:
        # OpenVINO ëª¨ë¸ ë¡œë“œ (ìƒëµí•˜ì§€ ì•ŠìŒ, ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        det_model = ie.read_model(det_xml, det_bin)
        det_compiled = ie.compile_model(det_model, "CPU")
        det_input_layer = det_compiled.input(0)
        det_output_layer = det_compiled.output(0)
        print(f"[{now_str()}] âœ… OpenVINO Detection ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        cls_model = ie.read_model(cls_xml, cls_bin)
        cls_compiled = ie.compile_model(cls_model, "CPU")
        cls_input_layer = cls_compiled.input(0)
        cls_output_layer = cls_compiled.output(0)
        _, _, cls_h, cls_w = cls_input_layer.shape
        print(f"[{now_str()}] âœ… OpenVINO Classification ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        deployed_model = torch.jit.load(DEPLOYMENT_FILE, map_location='cpu')
        deployed_model.eval()
        print(f"[{now_str()}] âœ… PyTorch Anomaly ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        # ============================================================
        # ğŸš¨ ì¹´ë©”ë¼ ì´ˆê¸°í™” ë¡œì§ ìˆ˜ì • (ìˆ˜ì •ëœ ë¶€ë¶„ 2/2) ğŸš¨
        # find_camera_by_vid_pidë¥¼ ì‚¬ìš©í•˜ì—¬ AD ì¹´ë©”ë¼ì˜ ê³ ì • ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        # ============================================================
        print(f"[{now_str()}] INFO System :: AD ì¹´ë©”ë¼ ê³ ìœ  ID ê¸°ë°˜ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        
        # AD ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œí•˜ê³ , PE ì¸ë±ìŠ¤ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.
        AD_CAMERA_INDEX, _ = find_camera_by_vid_pid()
        
        if AD_CAMERA_INDEX == -1:
            raise RuntimeError("AD ì¹´ë©”ë¼ (VID:PID)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ camera_init_robust.pyì˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

        print(f"[{now_str()}] âœ… AD ì¹´ë©”ë¼ ê³ ì • ì¸ë±ìŠ¤ í™•ë³´: {AD_CAMERA_INDEX}")
        
        # í™•ë³´ëœ ì¸ë±ìŠ¤ë¡œ ì¹´ë©”ë¼ë¥¼ ì—½ë‹ˆë‹¤.
        cap = cv2.VideoCapture(AD_CAMERA_INDEX)

        if cap.isOpened():
            # í•´ìƒë„ ë° ì†ì„± ì„¤ì •
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"[{now_str()}] âœ… ì›¹ìº  ì—´ê¸° ì„±ê³µ: ì¸ë±ìŠ¤ {AD_CAMERA_INDEX}")
        else:
             # cv2.VideoCaptureê°€ ì¸ë±ìŠ¤ì— ì‹¤íŒ¨í•˜ë©´ ì˜¤ë¥˜ ë°œìƒ
            raise RuntimeError(f"ì›¹ìº  ì¸ë±ìŠ¤ {AD_CAMERA_INDEX}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"[{now_str()}] âŒ CRITICAL: ì´ˆê¸°í™” ì‹¤íŒ¨ - {e}")
        sys.exit(1)


# =======================
# 6. ë©”ì¸ ì¶”ë¡  ë° ë°œí–‰ í•¨ìˆ˜
# (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# =======================

def run_inference_and_publish(client):
    """
    1. ì´ë¯¸ì§€ ìº¡ì²˜ ë° ì „ì²˜ë¦¬ (ì €ì¡°ë„ ê°œì„ , Dehazing)
    2. OpenVINO Detection/Classification
    3. PyTorch Anomaly Detection
    4. MQTTë¡œ ê²°ê³¼ ë°œí–‰
    """
    global last_frame_boxes
    
    start_time = time.time() # ì‹œì—°ìš©: FPS ì¸¡ì • ì‹œì‘
    
    # 1. í”„ë ˆì„ ìº¡ì²˜
    ret, frame = cap.read()
    if not ret:
        print(f"[{now_str()}] âŒ ERROR: í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        time.sleep(0.1)
        return

    # --------------------------
    # 1-1) ì „ì²˜ë¦¬: ì €ì¡°ë„ ê°œì„  ë° Dehazing
    # --------------------------
    enhanced = enhance_low_light(frame)
    dehazed = dehaze(enhanced)

    # --------------------------
    # 2) OpenVINO Detection (ì¥ì• ë¬¼ ê°ì§€)
    # --------------------------
    resized = cv2.resize(dehazed, (640, 640))
    # OpenVINO ì…ë ¥ í˜•íƒœ: BxCxHxW
    input_image = np.expand_dims(resized.transpose(2, 0, 1), 0).astype(np.float32)
    det_results = det_compiled([input_image])[det_output_layer][0]

    boxes, scores = [], []
    for det in det_results:
        # OpenVINO ì¶œë ¥ í¬ë§·ì— ë”°ë¼ (x_min, y_min, x_max, y_max, conf)
        x_min, y_min, x_max, y_max, conf = det
        if conf > 0.5:
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¢Œí‘œ ë³µì›
            x_min = int(x_min / 640 * dehazed.shape[1])
            y_min = int(y_min / 640 * dehazed.shape[0])
            x_max = int(x_max / 640 * dehazed.shape[1])
            y_max = int(y_max / 640 * dehazed.shape[0])
            # NMSë¥¼ ìœ„í•´ [x, y, w, h] í˜•íƒœë¡œ ì €ì¥
            boxes.append([x_min, y_min, x_max - x_min, y_max - y_min]) 
            scores.append(float(conf))

    filtered_boxes, _ = nms(boxes, scores)

    # --------------------------
    # 3) Frame smoothing (NMS ê¸°ë°˜)
    # --------------------------
    smoothed_boxes = []
    # ì´ì „ í”„ë ˆì„ê³¼ IoU 0.7 ì´ìƒì¸ ë°•ìŠ¤ëŠ” ì´ì „ ë°•ìŠ¤ ìœ„ì¹˜ë¥¼ ì‚¬ìš© (í”ë“¤ë¦¼ ë°©ì§€)
    for box in filtered_boxes:
        matched = False
        for prev_box in last_frame_boxes:
            if iou(box, prev_box) > 0.7:
                smoothed_boxes.append(prev_box)
                matched = True
                break
        if not matched:
            smoothed_boxes.append(box)
    last_frame_boxes = smoothed_boxes.copy() # ë‹¤ìŒ í”„ë ˆì„ì„ ìœ„í•´ ì €ì¥

    # --------------------------
    # 4) Classification & Anomaly Check
    # --------------------------
    detections = []
    anomaly_detected = False
    critical_ship_detected = False # ğŸš¨ CRITICAL ì¶©ëŒ ìœ„í—˜ì„ ìœ ë°œí•  ìˆ˜ ìˆëŠ” ë°° ê°ì§€
    
    for (x, y, w, h) in smoothed_boxes:
        # Classificationì„ ìœ„í•œ ì˜ì—­ ì¶”ì¶œ
        crop = dehazed[max(0, y-5):min(dehazed.shape[0], y+h+5), max(0, x-5):min(dehazed.shape[1], x+w+5)]
        if crop.size == 0: continue

        # Classification (OpenVINO)
        cls_resized = cv2.resize(crop, (cls_w, cls_h))
        cls_resized = cv2.cvtColor(cls_resized, cv2.COLOR_BGR2RGB)
        cls_input = np.expand_dims(cls_resized.transpose(2, 0, 1), 0).astype(np.float32) / 255.0

        cls_result = cls_compiled([cls_input])[cls_output_layer]
        class_id = int(np.argmax(cls_result))
        score_cls = float(np.max(cls_result))
        label_name = class_names[class_id]
        
        # ğŸš¨ ì¼ë°˜ 'Ship'ì„ ê°ì§€í–ˆì„ ë•Œ ì¶©ëŒ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨
        if label_name in ['Ship']: 
             # ì‹¤ì œ ì¶©ëŒ ìœ„í—˜ ë¡œì§ (ì˜ˆ: ê°ì²´ í¬ê¸°, ìœ„ì¹˜, ì†ë„)ì´ ì—†ìœ¼ë¯€ë¡œ ì„ì‹œë¡œ 'Ship' ê°ì§€ ì‹œ CRITICALë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
             critical_ship_detected = True

        # Anomaly Detection (PyTorch) - íƒì§€ëœ ê°ì²´ ì˜ì—­ì—ë§Œ ì ìš©
        pil_crop = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        input_tensor = inference_transforms(pil_crop).unsqueeze(0).to('cpu')
        
        with torch.no_grad():
            anomaly_score = deployed_model(input_tensor).item() 
        
        is_anomaly = anomaly_score > OPTIMAL_THRESHOLD
        if is_anomaly:
            anomaly_detected = True

        detections.append({
            "object_type": label_name,
            "confidence": round(score_cls, 2),
            "anomaly": is_anomaly,
            "anomaly_score": round(anomaly_score, 4),
            "box": [x, y, w, h] # x, y, width, height
        })

    # --------------------------
    # 5) MQTT ë°œí–‰
    # --------------------------
    
    # 5-1. ê¸°ë³¸ RAW ë°ì´í„° (ëª¨ë“  íƒì§€ ê²°ê³¼ í¬í•¨)
    raw_data = {
        "timestamp": now_str(),
        "module": AD_MODULE, # ğŸš¨ ìˆ˜ì •: ëª¨ë“ˆ ì´ë¦„ ëª…ì‹œ
        "level": "INFO",     # ğŸš¨ ìˆ˜ì •: INFO ë ˆë²¨ ëª…ì‹œ
        "detections": detections,
        "total_count": len(detections),
        "anomaly_count": sum(1 for d in detections if d['anomaly']),
    }
    raw_payload = json.dumps(raw_data)
    client.publish(RAW_TOPIC, raw_payload, qos=0)
    # ì‹œì—°ìš© ë¡œê·¸: RAW ë°ì´í„° ë°œí–‰ 
    end_time = time.time()
    fps = 1.0 / (end_time - start_time + 1e-6)
    print(f"[{now_str()}] INFO PUB :: {RAW_TOPIC} â†’ Sent {len(detections)} detections. (FPS: {fps:.1f})")


    # 5-2. ê²½ê³  ì´ë²¤íŠ¸ (Anomalyë‚˜ ì¤‘ìš” ê°ì²´ ê°ì§€ ì‹œ)
    if anomaly_detected or critical_ship_detected:
        
        # ğŸš¨ ë ˆë²¨ ë° ë©”ì‹œì§€ ê²°ì • ë¡œì§ ğŸš¨
        if anomaly_detected or critical_ship_detected:
            # ì´ìƒ ì§•í›„ë‚˜ ì¶©ëŒ ìœ„í—˜(Ship ê°ì§€)ì´ ìˆìœ¼ë©´ CRITICAL
            alert_level = "CRITICAL"
            alert_summary = f"ğŸš¨ ê¸´ê¸‰ ì¶©ëŒ/ì´ìƒ ì§•í›„! ì´ {len(detections)}ê°œ ê°ì²´ ì¤‘ {sum(1 for d in detections if d['anomaly'])}ê°œ ì´ìƒ ì§•í›„."
            
        elif any(d['object_type'] in ['Animal', 'Reef'] for d in detections):
            # Animal ë˜ëŠ” ReefëŠ” í•­í•´ì— ì£¼ì˜ê°€ í•„ìš”í•˜ë¯€ë¡œ WARNING
            alert_level = "WARNING"
            alert_summary = f"âš ï¸ í•­í•´ ì£¼ì˜! {', '.join(set(d['object_type'] for d in detections if d['object_type'] in ['Animal', 'Reef']))} ê°ì§€ë¨."
        else:
            return # ê²½ê³  ë°œí–‰ í•„ìš” ì—†ìŒ

        alert_data = {
            "timestamp": now_str(),
            "module": AD_MODULE, # ğŸš¨ ìˆ˜ì •: ëª¨ë“ˆ ì´ë¦„ ëª…ì‹œ
            "level": alert_level, # ğŸš¨ ìˆ˜ì •: ê²°ì •ëœ ë ˆë²¨ ì ìš©
            "message": alert_summary,
            "details": [d for d in detections if d['anomaly'] or d['object_type'] in ['Ship', 'Animal', 'Reef']],
        }
        alert_payload = json.dumps(alert_data)
        client.publish(ALERT_TOPIC, alert_payload, qos=1)
        # ì‹œì—°ìš© ë¡œê·¸: ê²½ê³  ë°œí–‰
        print(f"[{now_str()}] ğŸ“¢ {alert_level} PUB :: {ALERT_TOPIC} â†’ {alert_summary}")
        
    
    time.sleep(0.01) # 0.01ì´ˆ ëŒ€ê¸° (CPU ì ìœ ìœ¨ ê´€ë¦¬)


# ====================================================
# 7. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# ====================================================

def main():
    # 1. ëª¨ë¸ ë° ì¹´ë©”ë¼ ì´ˆê¸°í™”
    initialize_vision()

    # 2. MQTT í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²°
    client = mqtt.Client()
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print(f"[{now_str()}] INFO MQTT :: Client connected successfully (RC: {rc})")
        else:
            print(f"[{now_str()}] âŒ CRITICAL: MQTT Connection failed (RC: {rc})")
            sys.exit(1)
            
    client.on_connect = on_connect # ì½œë°± ì„¤ì •
    
    try:
        client.connect(BROKER, PORT, 60)
        client.loop_start() 
        print(f"[{now_str()}] INFO MQTT :: Client attempting connection to {BROKER}:{PORT}")
    except Exception as e:
        print(f"[{now_str()}] âŒ CRITICAL: MQTT ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    # 3. ë©”ì¸ ë£¨í”„
    try:
        while True:
            # GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° cv2.waitKey(1) ëŒ€ì‹  time.sleepì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            # cv2.imshowëŠ” ì œê±°í–ˆìœ¼ë¯€ë¡œ time.sleep(0.01) ì •ë„ë¥¼ ì¶”ê°€í•˜ì—¬ CPU ì ìœ ìœ¨ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
            run_inference_and_publish(client)
            
    except KeyboardInterrupt:
        print(f"\n[{now_str()}] INFO System :: Vision client stopped by user (Ctrl+C).")
    except Exception as e:
        print(f"\n[{now_str()}] âŒ ERROR System :: An unexpected error occurred: {e}")
    finally:
        client.loop_stop()
        client.disconnect() 
        print(f"[{now_str()}] INFO MQTT :: Client disconnected.")
        if cap is not None:
            cap.release()
        sys.exit(0)

if __name__ == "__main__":
    main()
